{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b48c2bff",
   "metadata": {},
   "source": [
    "Per il preprocessing serve fare una pipeline in cui:\n",
    "- vengono gestiti i valori Nan\n",
    "- viene fatto encoding o standardizzazione\n",
    "\n",
    "Pipeline diverse per tipi di dato diversi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "239c3daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.plotting import scatter_matrix\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from pandas.api.types import CategoricalDtype\n",
    "from scipy.stats import chi2_contingency\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "df = pd.read_csv('data.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b9f28dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 321457 entries, 0 to 321456\n",
      "Data columns (total 50 columns):\n",
      " #   Column          Non-Null Count   Dtype  \n",
      "---  ------          --------------   -----  \n",
      " 0   GENHLTH         320707 non-null  float64\n",
      " 1   PHYSHLTH        315181 non-null  float64\n",
      " 2   MENTHLTH        316891 non-null  float64\n",
      " 3   HLTHPLN1        320798 non-null  Int64  \n",
      " 4   PERSDOC2        320512 non-null  Int64  \n",
      " 5   MEDCOST         320812 non-null  Int64  \n",
      " 6   CHECKUP1        318370 non-null  float64\n",
      " 7   BPHIGH4         320806 non-null  Int64  \n",
      " 8   CHOLCHK         317268 non-null  float64\n",
      " 9   TOLDHI2         318789 non-null  Int64  \n",
      " 10  CVDINFR4        320086 non-null  Int64  \n",
      " 11  CVDCRHD4        318652 non-null  Int64  \n",
      " 12  CVDSTRK3        320613 non-null  Int64  \n",
      " 13  ASTHMA3         320590 non-null  Int64  \n",
      " 14  CHCSCNCR        320631 non-null  Int64  \n",
      " 15  CHCOCNCR        320822 non-null  Int64  \n",
      " 16  CHCCOPD1        319944 non-null  Int64  \n",
      " 17  HAVARTH3        319679 non-null  Int64  \n",
      " 18  ADDEPEV2        320240 non-null  Int64  \n",
      " 19  CHCKIDNY        320461 non-null  Int64  \n",
      " 20  DIABETE3        321457 non-null  object \n",
      " 21  MARITAL         320277 non-null  object \n",
      " 22  EDUCA           320862 non-null  float64\n",
      " 23  VETERAN3        321236 non-null  Int64  \n",
      " 24  EMPLOY1         320039 non-null  object \n",
      " 25  CHILDREN        320704 non-null  float64\n",
      " 26  INCOME2         276347 non-null  float64\n",
      " 27  INTERNET        321001 non-null  Int64  \n",
      " 28  QLACTLM2        319672 non-null  Int64  \n",
      " 29  USEEQUIP        320998 non-null  Int64  \n",
      " 30  BLIND           320548 non-null  Int64  \n",
      " 31  DECIDE          319749 non-null  Int64  \n",
      " 32  DIFFWALK        320049 non-null  Int64  \n",
      " 33  DIFFDRES        320868 non-null  Int64  \n",
      " 34  DIFFALON        320423 non-null  Int64  \n",
      " 35  SMOKE100        319492 non-null  Int64  \n",
      " 36  ALCDAY5         311116 non-null  float64\n",
      " 37  FRUITJU1        313269 non-null  float64\n",
      " 38  EXERANY2        319909 non-null  Int64  \n",
      " 39  STRENGTH        309017 non-null  float64\n",
      " 40  FLUSHOT6        319573 non-null  Int64  \n",
      " 41  PNEUVAC3        296843 non-null  Int64  \n",
      " 42  HIVTST6         310240 non-null  Int64  \n",
      " 43  _RACE           317366 non-null  object \n",
      " 44  _AGE_G          321457 non-null  float64\n",
      " 45  _BMI5CAT        321457 non-null  object \n",
      " 46  _SMOKER3        319296 non-null  float64\n",
      " 47  _PACAT1         308780 non-null  float64\n",
      " 48  NUMADULT_2      321457 non-null  float64\n",
      " 49  NutritionScore  295289 non-null  float64\n",
      "dtypes: Int64(29), float64(16), object(5)\n",
      "memory usage: 131.5+ MB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "binary_cols = ['HLTHPLN1','MEDCOST','TOLDHI2','CVDINFR4',\n",
    "            'CVDCRHD4','CVDSTRK3','ASTHMA3','CHCSCNCR','CHCOCNCR',\n",
    "            'CHCCOPD1','HAVARTH3','ADDEPEV2','CHCKIDNY','VETERAN3',\n",
    "            'INTERNET','QLACTLM2','USEEQUIP','BLIND','DECIDE',\n",
    "            'DIFFWALK','DIFFDRES','DIFFALON','SMOKE100','EXERANY2','FLUSHOT6',\n",
    "            'PNEUVAC3', 'HIVTST6', 'PERSDOC2', 'BPHIGH4'] \n",
    "\n",
    "nominal_cols = [\n",
    "    'MARITAL','EMPLOY1','_RACE', '_BMI5CAT'\n",
    "]\n",
    "\n",
    "numeric_cols = [\n",
    "    'PHYSHLTH','MENTHLTH','CHILDREN','NUMADULT_2',\n",
    "    'ALCDAY5', 'FRUITJU1','NutritionScore',  'STRENGTH'\n",
    "]\n",
    "\n",
    "ordinal = {\n",
    "    'GENHLTH':       [1,2,3,4,5],       # 1=Excellent â€¦ 5=Poor\n",
    "    'CHECKUP1':      [1,2,3,4,5,6,7,8], # \n",
    "    'CHOLCHK':       [1,2,3,4],         \n",
    "    '_AGE_G':        [1,2,3,4,5,6],     # 1=18â€“24 â€¦ 6=65+\n",
    "    '_PACAT1':       [1,2,3,4],         # 1=High active â€¦ 4=Inactive     \n",
    "    'EDUCA':         [1,2,3,4,5,6],     # 1=Less than high school â€¦ 6=Post-grad\n",
    "    'INCOME2':       [1,2,3,4,5,6,7,8], # 1=Less than $10K â€¦ 8=$75K or more \n",
    "    '_SMOKER3':      [1,2,3,4],         # 1=Current every day â€¦ 4=Never\n",
    "}\n",
    "\n",
    "\"\"\"\n",
    "# 2) Cast nominali a 'category' (manteniamo i codici numerici)\n",
    "for col in nominal_cols:\n",
    "    df[col] = df[col].astype('category')\n",
    "\n",
    "# 3) Cast ordinali a 'category' con ordered=True\n",
    "for col, cats in ordinal_asc.items():\n",
    "    cat_type = CategoricalDtype(categories=cats, ordered=True)\n",
    "    df[col] = df[col].astype(cat_type)\n",
    "\n",
    "for col, cats in ordinal_desc.items():\n",
    "    cat_type = CategoricalDtype(categories=cats, ordered=True)\n",
    "    df[col] = df[col].astype(cat_type)\n",
    "\"\"\"\n",
    "# Nominali: stringa coerente\n",
    "for col in nominal_cols:\n",
    "    df[col] = df[col].astype(str)\n",
    "    df[col] = df[col].replace(['nan', 'None', '-9223372036854775808'], np.nan)\n",
    "\n",
    "# Ordinali: forzati a float con NaN se conversione fallisce\n",
    "for col in list(ordinal.keys()):\n",
    "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "\n",
    "df[binary_cols] = df[binary_cols].astype('Int64')\n",
    "\n",
    "df[numeric_cols] = df[numeric_cols].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "\n",
    "df.info()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69b6507c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6v/1zb17jyj7kb910z5z0pnvx5c0000gn/T/ipykernel_63019/1465117484.py:4: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(df[col]):\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Rimuove ogni tipo categorico residuo\n",
    "for col in df.columns:\n",
    "    if pd.api.types.is_categorical_dtype(df[col]):\n",
    "        df[col] = df[col].astype(str)  # resetta tipo\n",
    "        try:\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "# Definizione feature e target\n",
    "X = df.drop(columns=['DIABETE3'])\n",
    "y = df['DIABETE3']\n",
    "\n",
    "# Split stratificato\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, stratify=y, test_size=0.2, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "450b85e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], dtype: object)\n",
      "Series([], dtype: object)\n"
     ]
    }
   ],
   "source": [
    "print(df.dtypes[df.dtypes == 'category'])         # devono essere 0\n",
    "print(X.dtypes[X.dtypes == 'category'])           # devono essere 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a562b4a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ðŸ“‚ CV Random Forest:   0%|          | 0/5 [00:52<?, ?it/s]/s]\n",
      "ðŸ” Valutazione modelli:   0%|          | 0/1 [00:52<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 61\u001b[0m\n\u001b[1;32m     58\u001b[0m X_fold_train, y_fold_train \u001b[38;5;241m=\u001b[39m X_train\u001b[38;5;241m.\u001b[39miloc[train_idx], y_train\u001b[38;5;241m.\u001b[39miloc[train_idx]\n\u001b[1;32m     59\u001b[0m X_fold_test,  y_fold_test  \u001b[38;5;241m=\u001b[39m X_train\u001b[38;5;241m.\u001b[39miloc[test_idx],  y_train\u001b[38;5;241m.\u001b[39miloc[test_idx]\n\u001b[0;32m---> 61\u001b[0m \u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_fold_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_fold_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m y_pred_fold \u001b[38;5;241m=\u001b[39m pipeline\u001b[38;5;241m.\u001b[39mpredict(X_fold_test)\n\u001b[1;32m     64\u001b[0m y_prob_fold \u001b[38;5;241m=\u001b[39m pipeline\u001b[38;5;241m.\u001b[39mpredict_proba(X_fold_test)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/DMML/lib/python3.11/site-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/DMML/lib/python3.11/site-packages/imblearn/pipeline.py:333\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m    331\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    332\u001b[0m         last_step_params \u001b[38;5;241m=\u001b[39m routed_params[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]]\n\u001b[0;32m--> 333\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_final_estimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mlast_step_params\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfit\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/DMML/lib/python3.11/site-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/DMML/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:489\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    478\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    479\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[1;32m    480\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[1;32m    481\u001b[0m ]\n\u001b[1;32m    483\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[1;32m    484\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[1;32m    485\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[1;32m    486\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[1;32m    487\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[1;32m    488\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[0;32m--> 489\u001b[0m trees \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthreads\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_trees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    505\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    506\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    507\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    508\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    510\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[1;32m    511\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/DMML/lib/python3.11/site-packages/sklearn/utils/parallel.py:74\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     69\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     70\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     71\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     73\u001b[0m )\n\u001b[0;32m---> 74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/DMML/lib/python3.11/site-packages/joblib/parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[1;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/DMML/lib/python3.11/site-packages/joblib/parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/DMML/lib/python3.11/site-packages/sklearn/utils/parallel.py:136\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    134\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/DMML/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:192\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap, missing_values_in_feature_mask)\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m class_weight \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced_subsample\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    190\u001b[0m         curr_sample_weight \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m compute_sample_weight(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m\"\u001b[39m, y, indices\u001b[38;5;241m=\u001b[39mindices)\n\u001b[0;32m--> 192\u001b[0m     \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurr_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    200\u001b[0m     tree\u001b[38;5;241m.\u001b[39m_fit(\n\u001b[1;32m    201\u001b[0m         X,\n\u001b[1;32m    202\u001b[0m         y,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    205\u001b[0m         missing_values_in_feature_mask\u001b[38;5;241m=\u001b[39mmissing_values_in_feature_mask,\n\u001b[1;32m    206\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/DMML/lib/python3.11/site-packages/sklearn/tree/_classes.py:472\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[0;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    462\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[1;32m    463\u001b[0m         splitter,\n\u001b[1;32m    464\u001b[0m         min_samples_split,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    469\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[1;32m    470\u001b[0m     )\n\u001b[0;32m--> 472\u001b[0m \u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    474\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    475\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, BaggingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score,\n",
    "                            f1_score, confusion_matrix, roc_auc_score, roc_curve, auc)\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from xgboost import XGBClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm  # âœ… Aggiunto tqdm per barre di avanzamento\n",
    "\n",
    "import Preprocessor  # assicurati che questo sia definito correttamente\n",
    "from Preprocessor import preprocessor\n",
    "\n",
    "\n",
    "# === MODELLI ===\n",
    "models = {\n",
    "    'Random Forest': RandomForestClassifier(random_state=42)\n",
    "    # Puoi scommentare altri modelli qui sotto se vuoi usarli:\n",
    "    # 'Logistic Regression': LogisticRegression(max_iter=500),\n",
    "    # 'AdaBoost': AdaBoostClassifier(random_state=42),\n",
    "    # 'Decision Tree': DecisionTreeClassifier(random_state=42),\n",
    "    # 'KNN': KNeighborsClassifier(),\n",
    "    # 'Bayesian': GaussianNB(),\n",
    "    # 'XGBoost': XGBClassifier(random_state=42)\n",
    "}\n",
    "\n",
    "# === STRATIFIED CV ===\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "n_classes = 3  # 0=no diabete, 1=prediabete, 2=diabete\n",
    "\n",
    "model_scores = {}\n",
    "roc_curves = {}\n",
    "conf_matrices = {}\n",
    "all_results = []\n",
    "\n",
    "# === LOOP PER MODELLO CON TQDM ===\n",
    "for model_name, model in tqdm(models.items(), desc=\"Valutazione modelli\"):\n",
    "\n",
    "    pipeline = Pipeline(steps=[\n",
    "        ('preprocessing', preprocessor),\n",
    "        ('smote', SMOTE(random_state=42)),\n",
    "        ('model', model)\n",
    "    ])\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    y_prob_all = []\n",
    "\n",
    "    # LOOP CON TQDM SUI FOLD\n",
    "    for fold_idx, (train_idx, test_idx) in enumerate(tqdm(skf.split(X_train, y_train), total=5, desc=f\"ðŸ“‚ CV {model_name}\")):\n",
    "        X_fold_train, y_fold_train = X_train.iloc[train_idx], y_train.iloc[train_idx]\n",
    "        X_fold_test,  y_fold_test  = X_train.iloc[test_idx],  y_train.iloc[test_idx]\n",
    "\n",
    "        pipeline.fit(X_fold_train, y_fold_train)\n",
    "\n",
    "        y_pred_fold = pipeline.predict(X_fold_test)\n",
    "        y_prob_fold = pipeline.predict_proba(X_fold_test)\n",
    "\n",
    "        y_true.extend(y_fold_test)\n",
    "        y_pred.extend(y_pred_fold)\n",
    "        y_prob_all.extend(y_prob_fold)\n",
    "\n",
    "    # === METRICHE ===\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    y_prob_all = np.array(y_prob_all)\n",
    "\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "    recall = recall_score(y_true, y_pred, average='macro')\n",
    "    f1 = f1_score(y_true, y_pred, average='macro')\n",
    "    roc_auc = roc_auc_score(label_binarize(y_true, classes=[0,1,2]),\n",
    "                            y_prob_all, average='macro', multi_class='ovr')\n",
    "\n",
    "    all_results.append({\n",
    "        'Model': model_name,\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1 Score': f1,\n",
    "        'ROC AUC': roc_auc\n",
    "    })\n",
    "\n",
    "    conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "    conf_matrices[model_name] = conf_matrix\n",
    "\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc_class = dict()\n",
    "    y_true_bin = label_binarize(y_true, classes=[0,1,2])\n",
    "\n",
    "    for i in range(n_classes):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_true_bin[:, i], y_prob_all[:, i])\n",
    "        roc_auc_class[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "    roc_curves[model_name] = (fpr, tpr, roc_auc_class)\n",
    "\n",
    "# === RISULTATI ===\n",
    "results_df = pd.DataFrame(all_results)\n",
    "print(results_df)\n",
    "\n",
    "# === ROC CURVES MULTICLASS ===\n",
    "for model_name, (fpr, tpr, roc_auc_class) in roc_curves.items():\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    for i in range(n_classes):\n",
    "        plt.plot(fpr[i], tpr[i], label=f'Class {i} (AUC = {roc_auc_class[i]:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.title(f'ROC Curve - {model_name}')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "# === CONFUSION MATRICES ===\n",
    "num_models = len(models)\n",
    "cols = 3\n",
    "rows = num_models // cols + int(num_models % cols > 0)\n",
    "\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(20, 5 * rows))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, (model_name, conf_matrix) in enumerate(conf_matrices.items()):\n",
    "    ax = axes[idx]\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False, ax=ax)\n",
    "    ax.set_title(f'{model_name}')\n",
    "    ax.set_xlabel('Predicted Label')\n",
    "    ax.set_ylabel('True Label')\n",
    "\n",
    "for idx in range(len(conf_matrices), len(axes)):\n",
    "    fig.delaxes(axes[idx])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DMML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
