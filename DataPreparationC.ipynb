{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3464baed",
   "metadata": {},
   "source": [
    "# Data Preparation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c355ea",
   "metadata": {},
   "source": [
    "Il dataset iniziale è il dataset completo delle interviste effettuate a oltre 400000 utenti.  Visto l'obiettivo di questo studio, ossia una classificazione multiclasse del diabete, verranno escluse dal dataset tutte quelle domande non utili alla generalizzazione, come info personali identificative dell'individuo intervistato o i suoi possedimenti.\n",
    "\n",
    "Verranno inoltre eliminate tutte quelle colonne derivate.\n",
    "\n",
    "Il tutto è stato possibile farlo consultando il notebook relativo al dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "924670a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 441456 entries, 0 to 441455\n",
      "Columns: 330 entries, _STATE to _AIDTST3\n",
      "dtypes: float64(323), object(7)\n",
      "memory usage: 1.1+ GB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "df = pd.read_csv('dmml_diabetes_db.csv')\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6140db3d",
   "metadata": {},
   "source": [
    "Le colonne da eliminare sono state trovate tramite codebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2236fc74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 252, 253, 254, 255, 256, 257, 259, 260, 261, 264, 265, 266, 267, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 296, 297, 306, 307, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 329, 231, 262]\n"
     ]
    }
   ],
   "source": [
    "# Colonne derivate da eliminare:\n",
    "dropped_cols = [\n",
    "    \"_RFHLTH\", \"_HCVU651\", \"_RFHYPE5\", \"_CHOLCHK\", \"_RFCHOL\", \"_MICHD\",\n",
    "    \"_LTASTH1\", \"_CASTHM1\", \"_ASTHMS1\", \"_DRDXAR1\", \"_PRACE1\", \"_MRACE1\",\n",
    "    \"_HISPANC\", \"_RACEG21\", \"_RACEGR3\", \"_RACE_G1\", \"_AGEG5YR\", \"_AGE65YR\",\n",
    "    \"_AGE80\", \"HTIN4\", \"HTM4\", \"WTKG3\", \"_RFBMI5\", \"_CHLDCNT\", \"_EDUCAG\",\n",
    "    \"_INCOMG\", \"_RFSMOK3\", \"DRNKANY5\", \"DROCDY3_\", \"_RFBING5\", \"_DRNKWEK\",\n",
    "    \"_RFDRHV5\", \"FTJUDA1_\", \"FRUTDA1_\", \"BEANDAY_\", \"GRENDAY_\", \"ORNGDAY_\",\n",
    "    \"VEGEDA1_\", \"_MISFRTN\", \"_MISVEGN\", \"_FRTRESP\", \"_VEGRESP\", \"_FRUTSUM\",\n",
    "    \"_VEGESUM\", \"_FRTLT1\", \"_VEGLT1\", \"_FRT16\", \"_VEG23\", \"_FRUITEX\",\n",
    "    \"_VEGETEX\", \"_TOTINDA\", \"MAXVO2_\", \"FC60_\", \"STRFREQ_\", \"PAMISS1_\",\n",
    "    \"_PAINDX1\", \"_PA150R2\", \"_PA300R2\", \"_PA30021\", \"_PASTRNG\", \"_PAREC1\",\n",
    "    \"_PASTAE1\", \"_LMTACT1\", \"_LMTWRK1\", \"_LMTSCL1\", \"_RFSEAT2\", \"_RFSEAT3\",\n",
    "    \"_AIDTST3\", \"_CHISPNC\", \"_BMI5\"\n",
    "]\n",
    "indices = [df.columns.get_loc(col) for col in dropped_cols if col in df.columns]\n",
    "print(indices)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "af9106cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns.get_loc('WEIGHT2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f34f71c",
   "metadata": {},
   "source": [
    "Tenendo BMI tolgo altezza e peso"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1fea25",
   "metadata": {},
   "source": [
    "colonne derivate + colonne non inerenti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1f7fb9c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eliminate 109 colonne.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "drop_indices = (\n",
    "    list(range(1, 14))    # 1–13\n",
    "    + list(range(16, 20))  # 16–19\n",
    "    + list(range(21, 25))  # 21–24\n",
    "    + list(range(55, 59))  # 55–58\n",
    "    + [64] + [65]          # 64, 65\n",
    "    + [197]                # 197\n",
    "    + list(range(222, 232))# 222–230\n",
    "    + [235]                # 235\n",
    "    + list(range(237, 251))# 237–250\n",
    "    + list(range(252, 258))# 252–257\n",
    "    + list(range(259, 263))# 259–262\n",
    "    + list(range(264, 268))# 264–267\n",
    "    + list(range(269, 294))# 269–293\n",
    "    + list(range(296, 298))# 296–297\n",
    "    + list(range(306, 308))# 306–307\n",
    "    + list(range(315, 327))# 315–326\n",
    "    + [329]                # 329\n",
    ")\n",
    "\n",
    "# Rimuovi eventuali duplicati e tieni gli indici validi\n",
    "drop_indices = sorted({i for i in drop_indices if 0 <= i < len(df.columns)})\n",
    "\n",
    "# Ottengo i nomi delle colonne e elimino\n",
    "cols_to_drop = [df.columns[i] for i in drop_indices]\n",
    "df = df.drop(columns=cols_to_drop)\n",
    "\n",
    "print(f\"Eliminate {len(cols_to_drop)} colonne.\")  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e84f07cf",
   "metadata": {},
   "source": [
    "Accorpamento in una singola colonna per due variabili che riguardano la stessa domanda, effettuata su linea fissa e su linea mobile, che le differenzia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e13be46b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colonne iniziali: 221\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ `NUMADULT_2` creata unendo `NUMADULT` e `HHADULT`.\n",
      "Colonne finali: 220\n",
      "Verifica presenza colonne originali:\n",
      "- `NUMADULT` presente? False\n",
      "- `HHADULT` presente? False\n"
     ]
    }
   ],
   "source": [
    "# Stampa il numero di colonne iniziali\n",
    "print(f\"Colonne iniziali: {df.shape[1]}\")\n",
    "\n",
    "# Definizione nomi colonne\n",
    "primary_col   = 'NUMADULT'\n",
    "secondary_col = 'HHADULT'\n",
    "new_col       = 'NUMADULT_2'\n",
    "\n",
    "# Controllo esistenza nuova colonna\n",
    "if new_col in df.columns:\n",
    "    print(f\"La colonna `{new_col}` esiste già. Operazione saltata.\")\n",
    "# Controllo esistenza colonne di origine\n",
    "elif not {primary_col, secondary_col}.issubset(df.columns):\n",
    "    missing = [c for c in (primary_col, secondary_col) if c not in df.columns]\n",
    "    print(f\"Impossibile creare `{new_col}`, mancano le colonne: {missing}\")\n",
    "else:\n",
    "    # Creazione nuova colonna con preferenza per primary_col\n",
    "    df[new_col] = df[primary_col].combine_first(df[secondary_col])\n",
    "    # Eliminazione colonne originali in-place\n",
    "    df.drop(columns=[primary_col, secondary_col], inplace=True)\n",
    "    print(f\"✅ `{new_col}` creata unendo `{primary_col}` e `{secondary_col}`.\")\n",
    "    \n",
    "# Info post-elaborazione\n",
    "print(f\"Colonne finali: {df.shape[1]}\")\n",
    "print(\"Verifica presenza colonne originali:\")\n",
    "print(f\"- `{primary_col}` presente? {primary_col in df.columns}\")\n",
    "print(f\"- `{secondary_col}` presente? {secondary_col in df.columns}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c75fd32",
   "metadata": {},
   "source": [
    "Butto via le colonne che contengono più del 30% di valori Nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c5aaaee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colonne eliminate per eccesso di NaN (> 30%):\n",
      "- LADULT\n",
      "- CADULT\n",
      "- POORHLTH\n",
      "- BPMEDS\n",
      "- ASTHNOW\n",
      "- DIABAGE2\n",
      "- PREGNANT\n",
      "- SMOKDAY2\n",
      "- STOPSMK2\n",
      "- LASTSMK2\n",
      "- AVEDRNK2\n",
      "- DRNK3GE5\n",
      "- MAXDRNKS\n",
      "- EXRACT11\n",
      "- EXEROFT1\n",
      "- EXERHMM1\n",
      "- EXRACT21\n",
      "- EXEROFT2\n",
      "- EXERHMM2\n",
      "- LMTJOIN3\n",
      "- ARTHDIS2\n",
      "- ARTHSOCL\n",
      "- JOINPAIN\n",
      "- FLSHTMY2\n",
      "- IMFVPLAC\n",
      "- HIVTSTD3\n",
      "- WHRTST10\n",
      "- PDIABTST\n",
      "- PREDIAB1\n",
      "- INSULIN\n",
      "- BLDSUGAR\n",
      "- FEETCHK2\n",
      "- DOCTDIAB\n",
      "- CHKHEMO3\n",
      "- FEETCHK\n",
      "- EYEEXAM\n",
      "- DIABEYE\n",
      "- DIABEDU\n",
      "- PAINACT2\n",
      "- QLMENTL2\n",
      "- QLSTRES2\n",
      "- QLHLTH2\n",
      "- CAREGIV1\n",
      "- CRGVREL1\n",
      "- CRGVLNG1\n",
      "- CRGVHRS1\n",
      "- CRGVPRB1\n",
      "- CRGVPERS\n",
      "- CRGVHOUS\n",
      "- CRGVMST2\n",
      "- CRGVEXPT\n",
      "- VIDFCLT2\n",
      "- VIREDIF3\n",
      "- VIPRFVS2\n",
      "- VINOCRE2\n",
      "- VIEYEXM2\n",
      "- VIINSUR2\n",
      "- VICTRCT4\n",
      "- VIGLUMA2\n",
      "- VIMACDG2\n",
      "- CIMEMLOS\n",
      "- CDHOUSE\n",
      "- CDASSIST\n",
      "- CDHELP\n",
      "- CDSOCIAL\n",
      "- CDDISCUS\n",
      "- WTCHSALT\n",
      "- LONGWTCH\n",
      "- DRADVISE\n",
      "- ASTHMAGE\n",
      "- ASATTACK\n",
      "- ASERVIST\n",
      "- ASDRVIST\n",
      "- ASRCHKUP\n",
      "- ASACTLIM\n",
      "- ASYMPTOM\n",
      "- ASNOSLEP\n",
      "- ASTHMED3\n",
      "- ASINHALR\n",
      "- HAREHAB1\n",
      "- STREHAB1\n",
      "- CVDASPRN\n",
      "- ASPUNSAF\n",
      "- RLIVPAIN\n",
      "- RDUCHART\n",
      "- RDUCSTRK\n",
      "- ARTTODAY\n",
      "- ARTHWGT\n",
      "- ARTHEXER\n",
      "- ARTHEDU\n",
      "- TETANUS\n",
      "- HPVADVC2\n",
      "- HPVADSHT\n",
      "- SHINGLE2\n",
      "- HADMAM\n",
      "- HOWLONG\n",
      "- HADPAP2\n",
      "- LASTPAP2\n",
      "- HPVTEST\n",
      "- HPLSTTST\n",
      "- HADHYST2\n",
      "- PROFEXAM\n",
      "- LENGEXAM\n",
      "- BLDSTOOL\n",
      "- LSTBLDS3\n",
      "- HADSIGM3\n",
      "- HADSGCO1\n",
      "- LASTSIG3\n",
      "- PCPSAAD2\n",
      "- PCPSADI1\n",
      "- PCPSARE1\n",
      "- PSATEST1\n",
      "- PSATIME\n",
      "- PCPSARS1\n",
      "- PCPSADE1\n",
      "- SCNTMNY1\n",
      "- SCNTMEL1\n",
      "- SCNTPAID\n",
      "- SCNTWRK1\n",
      "- SCNTLPAD\n",
      "- SCNTLWK1\n",
      "- SXORIENT\n",
      "- TRNSGNDR\n",
      "- RCSGENDR\n",
      "- RCSRLTN2\n",
      "- CASTHDX2\n",
      "- CASTHNO2\n",
      "- EMTSUPRT\n",
      "- LSATISFY\n",
      "- ADPLEASR\n",
      "- ADDOWN\n",
      "- ADSLEEP\n",
      "- ADENERGY\n",
      "- ADEAT1\n",
      "- ADFAIL\n",
      "- ADTHINK\n",
      "- ADMOVE\n",
      "- MISTMNT\n",
      "- ADANXEV\n",
      "- _CRACE1\n",
      "- _CPRACE\n",
      "- _CLLCPWT\n",
      "- _DUALCOR\n",
      "- METVL11_\n",
      "- METVL21_\n",
      "- ACTIN11_\n",
      "- ACTIN21_\n",
      "- PADUR1_\n",
      "- PADUR2_\n",
      "- PAFREQ1_\n",
      "- PAFREQ2_\n",
      "- _MINAC11\n",
      "- _MINAC21\n",
      "- PAMIN11_\n",
      "- PAMIN21_\n",
      "- PA1MIN_\n",
      "- PAVIG11_\n",
      "- PAVIG21_\n",
      "- PA1VIGM_\n",
      "- _FLSHOT6\n",
      "- _PNEUMO2\n",
      "Numero colonne attuali: 59\n"
     ]
    }
   ],
   "source": [
    "# Soglia di NaN (30%)\n",
    "threshold = 0.30\n",
    "# Calcola la percentuale di NaN per colonna\n",
    "nan_ratio = df.isna().mean()\n",
    "# Trova colonne da eliminare\n",
    "cols_to_drop = nan_ratio[nan_ratio > threshold].index.tolist()\n",
    "# Stampa e rimuovi\n",
    "if cols_to_drop:\n",
    "    print(\"Colonne eliminate per eccesso di NaN (> 30%):\")\n",
    "    for col in cols_to_drop:\n",
    "        print(f\"- {col}\")\n",
    "    df = df.drop(columns=cols_to_drop)\n",
    "else:\n",
    "    print(\"Nessuna colonna supera il 30% di valori NaN.\")\n",
    "print(f\"Numero colonne attuali: {df.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4c3a1e45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Righe originali: 441456\n",
      "Righe dopo il drop: 321835\n"
     ]
    }
   ],
   "source": [
    "#proviamo a droppare le righe che contengon valori nulli.\n",
    "print(f\"Righe originali: {df.shape[0]}\")\n",
    "df = df.dropna()\n",
    "print(f\"Righe dopo il drop: {df.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b11c4a",
   "metadata": {},
   "source": [
    "Aggiusto la variabile target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9951b419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Righe eliminate: 378\n",
      "Righe rimanenti: 321457\n"
     ]
    }
   ],
   "source": [
    "#droppo le righe che hanno diabete3 pari a 7 o 9 (non lo so/ nessuna risposta)\n",
    "before = df.shape[0]\n",
    "df = df[~df['DIABETE3'].isin([7, 9])]\n",
    "after = df.shape[0]\n",
    "\n",
    "mapping_DIABETE3 = {\n",
    "    1: 'Diabetes',\n",
    "    2: 'NoDiabetes',\n",
    "    3: 'NoDiabetes',\n",
    "    4: \"PreDiabetes\", \n",
    "}\n",
    "df['DIABETE3'] = df['DIABETE3'].map(mapping_DIABETE3)\n",
    "\n",
    "print(f\"Righe eliminate: {before - after}\")\n",
    "print(f\"Righe rimanenti: {after}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e72479",
   "metadata": {},
   "source": [
    "Ci occupiamo adesso delle variabili la cui codifica va cambiata per migliorare l'interpretazione nei modelli.\n",
    "\n",
    "Le variabili relative al consumo di cibo verranno tutte converitite in consumo mensile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "85c60bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def freq_food_to_monthly(code):\n",
    "    # valori missing/refused\n",
    "    if code in (777, 999) or pd.isna(code):\n",
    "        return np.nan\n",
    "    # mai\n",
    "    if code == 555:\n",
    "        return 0.0\n",
    "    # volte per giorno → moltiplico 30 giorni\n",
    "    if 101 <= code <= 199:\n",
    "        return (code - 100) * 30.0\n",
    "    # volte per settimana → moltiplico 4.345 settimane \n",
    "    if 201 <= code <= 299:\n",
    "        return (code - 200) * 4.345\n",
    "    # meno di 1 al mese → stimo 0.5\n",
    "    if code == 300:\n",
    "        return 0.5\n",
    "    # volte per mese diretto\n",
    "    if 301 <= code <= 399:\n",
    "        return code - 300\n",
    "    # altrimenti missing\n",
    "    return np.nan\n",
    "\n",
    "for var in ['FRUITJU1','FRUIT1','FVBEANS','FVGREEN','FVORANG','VEGETAB1']:\n",
    "    df[f'{var}'] = df[var].apply(freq_food_to_monthly)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c040bc2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def strength_to_weekly(code):\n",
    "    if code in (777, 999) or pd.isna(code):\n",
    "        return np.nan\n",
    "    if code == 888:\n",
    "        return 0.0\n",
    "    if 101 <= code <= 199:\n",
    "        return code - 100\n",
    "    if 201 <= code <= 299:\n",
    "        # converto il valore mensile in frequenza settimanale\n",
    "        return (code - 200) / 4.345\n",
    "    return np.nan\n",
    "\n",
    "df['STRENGTH'] = df['STRENGTH'].apply(strength_to_weekly) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "296906f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def alco_days_to_weekly(code):\n",
    "    if code in (777, 999) or pd.isna(code):\n",
    "        return np.nan\n",
    "    if code == 888:\n",
    "        return 0.0\n",
    "    if 101 <= code <= 199:\n",
    "        # giorni a settimana\n",
    "        return code - 100\n",
    "    if 201 <= code <= 299:\n",
    "        # giorni in 30 giorni → giorni/settimana\n",
    "        return (code - 200) / 4.345\n",
    "    return np.nan\n",
    "\n",
    "df['ALCDAY5'] = df['ALCDAY5'].apply(alco_days_to_weekly)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af9ab48b",
   "metadata": {},
   "source": [
    "Trasformo le colonne in binarie per migliore interpretazione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e71f6ea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BPHIGH4\n",
      "3.0    172496\n",
      "1.0    142902\n",
      "4.0      3463\n",
      "2.0      1945\n",
      "7.0       470\n",
      "9.0       181\n",
      "Name: count, dtype: int64\n",
      "PERSDOC2\n",
      "1.0    261598\n",
      "3.0     32736\n",
      "2.0     26178\n",
      "7.0       576\n",
      "9.0       369\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df['BPHIGH4'].unique()\n",
    "print(df['BPHIGH4'].value_counts(dropna=False))\n",
    "\n",
    "\n",
    "print(df['PERSDOC2'].value_counts(dropna=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b100d801",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['PERSDOC2'] = pd.Series(np.select(\n",
    "    [\n",
    "        df['PERSDOC2'].isin([1, 2]),  # rischio\n",
    "        df['PERSDOC2'] == 3           # no rischio\n",
    "    ],\n",
    "    [\n",
    "        1,  # rischio\n",
    "        0   # no rischio\n",
    "    ],\n",
    "    default=np.nan  # incerti, rifiutati, mancanti\n",
    "), index=df.index).astype('Int64')  # nullable integer per compatibilità con imputazione\n",
    "\n",
    "df['BPHIGH4'] = pd.Series(np.select(\n",
    "    [\n",
    "        df['BPHIGH4'].isin([1, 2, 4]),  # rischio\n",
    "        df['BPHIGH4'] == 3              # no rischio\n",
    "    ],\n",
    "    [\n",
    "        1,  # rischio\n",
    "        0   # no rischio\n",
    "    ],\n",
    "    default=np.nan  # incerti, rifiutati, mancanti\n",
    "), index=df.index).astype('Int64')  # nullable integer per compatibilità con imputazione\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "34b5e01c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 321457 entries, 0 to 441455\n",
      "Data columns (total 59 columns):\n",
      " #   Column      Non-Null Count   Dtype  \n",
      "---  ------      --------------   -----  \n",
      " 0   _STATE      321457 non-null  float64\n",
      " 1   GENHLTH     321457 non-null  float64\n",
      " 2   PHYSHLTH    321457 non-null  float64\n",
      " 3   MENTHLTH    321457 non-null  float64\n",
      " 4   HLTHPLN1    321457 non-null  float64\n",
      " 5   PERSDOC2    320512 non-null  Int64  \n",
      " 6   MEDCOST     321457 non-null  float64\n",
      " 7   CHECKUP1    321457 non-null  float64\n",
      " 8   BPHIGH4     320806 non-null  Int64  \n",
      " 9   BLOODCHO    321457 non-null  float64\n",
      " 10  CHOLCHK     321457 non-null  float64\n",
      " 11  TOLDHI2     321457 non-null  float64\n",
      " 12  CVDINFR4    321457 non-null  float64\n",
      " 13  CVDCRHD4    321457 non-null  float64\n",
      " 14  CVDSTRK3    321457 non-null  float64\n",
      " 15  ASTHMA3     321457 non-null  float64\n",
      " 16  CHCSCNCR    321457 non-null  float64\n",
      " 17  CHCOCNCR    321457 non-null  float64\n",
      " 18  CHCCOPD1    321457 non-null  float64\n",
      " 19  HAVARTH3    321457 non-null  float64\n",
      " 20  ADDEPEV2    321457 non-null  float64\n",
      " 21  CHCKIDNY    321457 non-null  float64\n",
      " 22  DIABETE3    321457 non-null  object \n",
      " 23  SEX         321457 non-null  float64\n",
      " 24  MARITAL     321457 non-null  float64\n",
      " 25  EDUCA       321457 non-null  float64\n",
      " 26  VETERAN3    321457 non-null  float64\n",
      " 27  EMPLOY1     321457 non-null  float64\n",
      " 28  CHILDREN    321457 non-null  float64\n",
      " 29  INCOME2     321457 non-null  float64\n",
      " 30  INTERNET    321457 non-null  float64\n",
      " 31  QLACTLM2    321457 non-null  float64\n",
      " 32  USEEQUIP    321457 non-null  float64\n",
      " 33  BLIND       321457 non-null  float64\n",
      " 34  DECIDE      321457 non-null  float64\n",
      " 35  DIFFWALK    321457 non-null  float64\n",
      " 36  DIFFDRES    321457 non-null  float64\n",
      " 37  DIFFALON    321457 non-null  float64\n",
      " 38  SMOKE100    321457 non-null  float64\n",
      " 39  USENOW3     321457 non-null  float64\n",
      " 40  ALCDAY5     318300 non-null  float64\n",
      " 41  FRUITJU1    315065 non-null  float64\n",
      " 42  FRUIT1      317131 non-null  float64\n",
      " 43  FVBEANS     315422 non-null  float64\n",
      " 44  FVGREEN     317480 non-null  float64\n",
      " 45  FVORANG     317160 non-null  float64\n",
      " 46  VEGETAB1    316272 non-null  float64\n",
      " 47  EXERANY2    321457 non-null  float64\n",
      " 48  STRENGTH    317938 non-null  float64\n",
      " 49  SEATBELT    321457 non-null  float64\n",
      " 50  FLUSHOT6    321457 non-null  float64\n",
      " 51  PNEUVAC3    321457 non-null  float64\n",
      " 52  HIVTST6     321457 non-null  float64\n",
      " 53  _RACE       321457 non-null  float64\n",
      " 54  _AGE_G      321457 non-null  float64\n",
      " 55  _BMI5CAT    321457 non-null  float64\n",
      " 56  _SMOKER3    321457 non-null  float64\n",
      " 57  _PACAT1     321457 non-null  float64\n",
      " 58  NUMADULT_2  321457 non-null  float64\n",
      "dtypes: Int64(2), float64(56), object(1)\n",
      "memory usage: 147.8+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "591eb69c",
   "metadata": {},
   "source": [
    "Trasformo nelle colonne binarie la codifica di no (2) in 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "18ee46e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['BLOODCHO'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7411687c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<IntegerArray>\n",
      "[1, 0, <NA>]\n",
      "Length: 3, dtype: Int64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<IntegerArray>\n",
      "[0, 1, <NA>]\n",
      "Length: 3, dtype: Int64\n",
      "<IntegerArray>\n",
      "[1]\n",
      "Length: 1, dtype: Int64\n",
      "<IntegerArray>\n",
      "[1, 0, <NA>]\n",
      "Length: 3, dtype: Int64\n",
      "<IntegerArray>\n",
      "[0, <NA>, 1]\n",
      "Length: 3, dtype: Int64\n",
      "<IntegerArray>\n",
      "[0, 1, <NA>]\n",
      "Length: 3, dtype: Int64\n",
      "<IntegerArray>\n",
      "[0, 1, <NA>]\n",
      "Length: 3, dtype: Int64\n",
      "<IntegerArray>\n",
      "[1, 0, <NA>]\n",
      "Length: 3, dtype: Int64\n",
      "<IntegerArray>\n",
      "[0, 1, <NA>]\n",
      "Length: 3, dtype: Int64\n",
      "<IntegerArray>\n",
      "[0, 1, <NA>]\n",
      "Length: 3, dtype: Int64\n",
      "<IntegerArray>\n",
      "[1, 0, <NA>]\n",
      "Length: 3, dtype: Int64\n",
      "<IntegerArray>\n",
      "[1, 0, <NA>]\n",
      "Length: 3, dtype: Int64\n",
      "<IntegerArray>\n",
      "[1, 0, <NA>]\n",
      "Length: 3, dtype: Int64\n",
      "<IntegerArray>\n",
      "[0, <NA>, 1]\n",
      "Length: 3, dtype: Int64\n",
      "<IntegerArray>\n",
      "[0, 1, <NA>]\n",
      "Length: 3, dtype: Int64\n",
      "<IntegerArray>\n",
      "[0, 1, <NA>]\n",
      "Length: 3, dtype: Int64\n",
      "<IntegerArray>\n",
      "[1, 0, <NA>]\n",
      "Length: 3, dtype: Int64\n",
      "<IntegerArray>\n",
      "[1, 0, <NA>]\n",
      "Length: 3, dtype: Int64\n",
      "<IntegerArray>\n",
      "[0, 1, <NA>]\n",
      "Length: 3, dtype: Int64\n",
      "<IntegerArray>\n",
      "[0, 1, <NA>]\n",
      "Length: 3, dtype: Int64\n",
      "<IntegerArray>\n",
      "[1, 0, <NA>]\n",
      "Length: 3, dtype: Int64\n",
      "<IntegerArray>\n",
      "[1, 0, <NA>]\n",
      "Length: 3, dtype: Int64\n",
      "<IntegerArray>\n",
      "[1, 0, <NA>]\n",
      "Length: 3, dtype: Int64\n",
      "<IntegerArray>\n",
      "[1, 0, <NA>]\n",
      "Length: 3, dtype: Int64\n",
      "<IntegerArray>\n",
      "[0, 1, <NA>]\n",
      "Length: 3, dtype: Int64\n",
      "<IntegerArray>\n",
      "[1, 0, <NA>]\n",
      "Length: 3, dtype: Int64\n",
      "<IntegerArray>\n",
      "[1, 0, <NA>]\n",
      "Length: 3, dtype: Int64\n",
      "<IntegerArray>\n",
      "[1, 0, <NA>]\n",
      "Length: 3, dtype: Int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "def to_binary(series, yes_value=1, no_value=2):\n",
    "    \"\"\"\n",
    "    Trasforma una Serie pandas con codifica 1=yes, 2=no in 0/1.\n",
    "    - yes_value  → 1\n",
    "    - no_value   → 0\n",
    "    - tutti gli altri valori → np.nan\n",
    "    \"\"\"\n",
    "    return series.map({yes_value: 1, no_value: 0}).astype('Int64')\n",
    "\n",
    "# Esempio di utilizzo:\n",
    "binary_cols = ['HLTHPLN1','MEDCOST','BLOODCHO','TOLDHI2','CVDINFR4',\n",
    "               'CVDCRHD4','CVDSTRK3','ASTHMA3','CHCSCNCR','CHCOCNCR',\n",
    "               'CHCCOPD1','HAVARTH3','ADDEPEV2','CHCKIDNY','VETERAN3',\n",
    "               'INTERNET','QLACTLM2','USEEQUIP','BLIND','DECIDE',\n",
    "               'DIFFWALK','DIFFDRES','DIFFALON','SMOKE100','EXERANY2','FLUSHOT6',\n",
    "               'PNEUVAC3', 'HIVTST6'] \n",
    "\n",
    "for col in binary_cols:\n",
    "    if col in df.columns:\n",
    "        df[f'{col}'] = to_binary(df[col])\n",
    "        print(df[f'{col}'].unique())\n",
    "    else:\n",
    "        print(f\"Colonna `{col}` non trovata nel DataFrame. Operazione saltata.\")\n",
    "        \n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "970f13da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IntegerArray>\n",
       "[1]\n",
       "Length: 1, dtype: Int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['BLOODCHO'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "655c4d3d",
   "metadata": {},
   "source": [
    "In alcune variabili la codifica dei valori non lo so/ rifiutato è differente. I valori con questo significato verranno trasformati in valori Nan. La loro frequenza è bassa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0417369d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista dei codici da trattare come NaN\n",
    "missing_codes = [7, 9]\n",
    "\n",
    "# Elenco delle colonne *da saltare* (quelle in cui quei codici non sono missing)\n",
    "exceptions = [\n",
    "    'PHYSHLTH', 'MENTHLTH', 'CHILDREN', 'NUMADULT_2',\n",
    "    '_STATE', 'EMPLOY1', 'INCOME2', '_RACE'\n",
    "]\n",
    "\n",
    "# Calcolo le colonne *su cui* voglio fare il replace\n",
    "cols_to_clean = [c for c in df.columns if c not in exceptions]\n",
    "\n",
    "# Applico il replace solo su quelle\n",
    "df[cols_to_clean] = df[cols_to_clean].replace(missing_codes, np.nan)\n",
    "\n",
    "\n",
    "#in employ1 e _race togliere solo il 9 \n",
    "\n",
    "#da income2, physhlth, menthlth,  togliere 77 e 99\n",
    "#in children 88 = 0 e togliere 99\n",
    "\n",
    "# 1) EMPLOY1 e _RACE: codice “9” → NaN, poi category\n",
    "df[['EMPLOY1','_RACE']] = (\n",
    "    df[['EMPLOY1','_RACE']]\n",
    "    .replace(9, np.nan)\n",
    ")\n",
    "\n",
    "# 2) INCOME2, PHYSHLTH, MENTHLTH: codici “77” e “99” → NaN\n",
    "#    - Income2 resta categorica\n",
    "#    - PHYSHLTH e MENTHLTH sono numeriche (giorni), quindi float\n",
    "df['INCOME2'] = (\n",
    "    df['INCOME2']\n",
    "    .replace([77,99], np.nan)\n",
    ")\n",
    "df[['PHYSHLTH','MENTHLTH']] = (\n",
    "    df[['PHYSHLTH','MENTHLTH']]\n",
    "    .replace({77: np.nan, 99: np.nan, 88: 0})\n",
    ")\n",
    "\n",
    "# 3) CHILDREN: codice “88” → 0 (nessun bambino), “99” → NaN\n",
    "df['CHILDREN'] = (\n",
    "    df['CHILDREN']\n",
    "    .replace({88: 0, 99: np.nan})\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a8908807",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_STATE: 0.00% NaN\n",
      "GENHLTH: 0.23% NaN\n",
      "PHYSHLTH: 1.95% NaN\n",
      "MENTHLTH: 1.42% NaN\n",
      "HLTHPLN1: 0.21% NaN\n",
      "PERSDOC2: 0.29% NaN\n",
      "MEDCOST: 0.20% NaN\n",
      "CHECKUP1: 0.96% NaN\n",
      "BPHIGH4: 0.20% NaN\n",
      "BLOODCHO: 0.00% NaN\n",
      "CHOLCHK: 1.30% NaN\n",
      "TOLDHI2: 0.83% NaN\n",
      "CVDINFR4: 0.43% NaN\n",
      "CVDCRHD4: 0.87% NaN\n",
      "CVDSTRK3: 0.26% NaN\n",
      "ASTHMA3: 0.27% NaN\n",
      "CHCSCNCR: 0.26% NaN\n",
      "CHCOCNCR: 0.20% NaN\n",
      "CHCCOPD1: 0.47% NaN\n",
      "HAVARTH3: 0.55% NaN\n",
      "ADDEPEV2: 0.38% NaN\n",
      "CHCKIDNY: 0.31% NaN\n",
      "DIABETE3: 0.00% NaN\n",
      "SEX: 0.00% NaN\n",
      "MARITAL: 0.37% NaN\n",
      "EDUCA: 0.19% NaN\n",
      "VETERAN3: 0.07% NaN\n",
      "EMPLOY1: 0.44% NaN\n",
      "CHILDREN: 0.23% NaN\n",
      "INCOME2: 14.03% NaN\n",
      "INTERNET: 0.14% NaN\n",
      "QLACTLM2: 0.56% NaN\n",
      "USEEQUIP: 0.14% NaN\n",
      "BLIND: 0.28% NaN\n",
      "DECIDE: 0.53% NaN\n",
      "DIFFWALK: 0.44% NaN\n",
      "DIFFDRES: 0.18% NaN\n",
      "DIFFALON: 0.32% NaN\n",
      "SMOKE100: 0.61% NaN\n",
      "USENOW3: 0.34% NaN\n",
      "ALCDAY5: 3.22% NaN\n",
      "FRUITJU1: 2.55% NaN\n",
      "FRUIT1: 1.97% NaN\n",
      "FVBEANS: 3.08% NaN\n",
      "FVGREEN: 2.14% NaN\n",
      "FVORANG: 2.41% NaN\n",
      "VEGETAB1: 2.25% NaN\n",
      "EXERANY2: 0.48% NaN\n",
      "STRENGTH: 3.87% NaN\n",
      "SEATBELT: 0.45% NaN\n",
      "FLUSHOT6: 0.59% NaN\n",
      "PNEUVAC3: 7.66% NaN\n",
      "HIVTST6: 3.49% NaN\n",
      "_RACE: 1.27% NaN\n",
      "_AGE_G: 0.00% NaN\n",
      "_BMI5CAT: 0.00% NaN\n",
      "_SMOKER3: 0.67% NaN\n",
      "_PACAT1: 3.94% NaN\n",
      "NUMADULT_2: 0.00% NaN\n"
     ]
    }
   ],
   "source": [
    "# Calcola la frazione di NaN per colonna e moltiplica per 100\n",
    "nan_perc = df.isna().mean() * 100\n",
    "\n",
    "# Stampa nome colonna e percentuale formattata\n",
    "for col, perc in nan_perc.items():\n",
    "    print(f\"{col}: {perc:.2f}% NaN\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd20e531",
   "metadata": {},
   "source": [
    "Cambiamo adesso il tipo delle variabili"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "790899e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom pandas.api.types import CategoricalDtype\\n\\n\\nnominal_cols = [\\n    \\'_STATE\\',\\'SEX\\',\\'MARITAL\\',\\'EMPLOY1\\',\\'_RACE\\', \\'_BMI5CAT\\'\\n]\\n\\n# definiamo quali ordinali hanno codifica \"1 = best, ↑ = worse\"\\nordinal_asc = {\\n    \\'GENHLTH\\':       [1,2,3,4,5],       # 1=Excellent … 5=Poor\\n    \\'CHECKUP1\\':      [1,2,3,4,5,6,7,8], # \\n    \\'CHOLCHK\\':       [1,2,3,4],         \\n    \\'_AGE_G\\':        [1,2,3,4,5,6],     # 1=18–24 … 6=65+\\n    \\'_PACAT1\\':       [1,2,3,4],         # 1=High active … 4=Inactive\\n    \\'SEATBELT\\':      [1,2,3,4,5]        # 1=Always … 5=Never (invertito)\\n}\\n\\n# e quali ordinali hanno codifica \"1 = worst, ↑ = better\" (e.g. lower code = peggiore)\\nordinal_desc = {\\n    \\'EDUCA\\':         [6,5,4,3,2,1],     # 1=None … 6=Post-grad (invertito)\\n    \\'INCOME2\\':       [8,7,6,5,4,3,2,1],     # 1=Less than $10K … 6=$75K or more\\n    \\'_SMOKER3\\':      [4,3,2,1] ,         # 1=Current every day … 4=Never\\n    \\'USENOW3\\':       [3,2,1]          # 1=Every day … 3=Not at all (invertito)\\n}\\n\\n# 2) Cast nominali a \\'category\\' (manteniamo i codici numerici)\\nfor col in nominal_cols:\\n    df[col] = df[col].astype(\\'category\\')\\n\\n# 3) Cast ordinali a \\'category\\' con ordered=True\\nfor col, cats in ordinal_asc.items():\\n    cat_type = CategoricalDtype(categories=cats, ordered=True)\\n    df[col] = df[col].astype(cat_type)\\n\\nfor col, cats in ordinal_desc.items():\\n    cat_type = CategoricalDtype(categories=cats, ordered=True)\\n    df[col] = df[col].astype(cat_type)\\n\\n# 4) Le vere variabili continue in float\\nnumeric_cols = [\\n    \\'PHYSHLTH\\',\\'MENTHLTH\\',\\'CHILDREN\\',\\'NUMADULT_2\\',\\n    \\'ALCDAY5\\', \\'FRUITJU1\\',\\'FRUIT1\\', \\'FVBEANS\\',\\'FVGREEN\\',\\n    \\'FVORANG\\',\\'VEGETAB1\\',  \\'STRENGTH\\'\\n]\\n\\ndf[numeric_cols] = df[numeric_cols].apply(pd.to_numeric, errors=\\'coerce\\')\\n\\n# 5) Controllo finale\\nprint(\"Dtypes finali:\")\\nprint(df[nominal_cols + list(ordinal_asc) + list(ordinal_desc) + numeric_cols].dtypes)\\n'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "from pandas.api.types import CategoricalDtype\n",
    "\n",
    "\n",
    "nominal_cols = [\n",
    "    '_STATE','SEX','MARITAL','EMPLOY1','_RACE', '_BMI5CAT'\n",
    "]\n",
    "\n",
    "# definiamo quali ordinali hanno codifica \"1 = best, ↑ = worse\"\n",
    "ordinal_asc = {\n",
    "    'GENHLTH':       [1,2,3,4,5],       # 1=Excellent … 5=Poor\n",
    "    'CHECKUP1':      [1,2,3,4,5,6,7,8], # \n",
    "    'CHOLCHK':       [1,2,3,4],         \n",
    "    '_AGE_G':        [1,2,3,4,5,6],     # 1=18–24 … 6=65+\n",
    "    '_PACAT1':       [1,2,3,4],         # 1=High active … 4=Inactive\n",
    "    'SEATBELT':      [1,2,3,4,5]        # 1=Always … 5=Never (invertito)\n",
    "}\n",
    "\n",
    "# e quali ordinali hanno codifica \"1 = worst, ↑ = better\" (e.g. lower code = peggiore)\n",
    "ordinal_desc = {\n",
    "    'EDUCA':         [6,5,4,3,2,1],     # 1=None … 6=Post-grad (invertito)\n",
    "    'INCOME2':       [8,7,6,5,4,3,2,1],     # 1=Less than $10K … 6=$75K or more\n",
    "    '_SMOKER3':      [4,3,2,1] ,         # 1=Current every day … 4=Never\n",
    "    'USENOW3':       [3,2,1]          # 1=Every day … 3=Not at all (invertito)\n",
    "}\n",
    "\n",
    "# 2) Cast nominali a 'category' (manteniamo i codici numerici)\n",
    "for col in nominal_cols:\n",
    "    df[col] = df[col].astype('category')\n",
    "\n",
    "# 3) Cast ordinali a 'category' con ordered=True\n",
    "for col, cats in ordinal_asc.items():\n",
    "    cat_type = CategoricalDtype(categories=cats, ordered=True)\n",
    "    df[col] = df[col].astype(cat_type)\n",
    "\n",
    "for col, cats in ordinal_desc.items():\n",
    "    cat_type = CategoricalDtype(categories=cats, ordered=True)\n",
    "    df[col] = df[col].astype(cat_type)\n",
    "\n",
    "# 4) Le vere variabili continue in float\n",
    "numeric_cols = [\n",
    "    'PHYSHLTH','MENTHLTH','CHILDREN','NUMADULT_2',\n",
    "    'ALCDAY5', 'FRUITJU1','FRUIT1', 'FVBEANS','FVGREEN',\n",
    "    'FVORANG','VEGETAB1',  'STRENGTH'\n",
    "]\n",
    "\n",
    "df[numeric_cols] = df[numeric_cols].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# 5) Controllo finale\n",
    "print(\"Dtypes finali:\")\n",
    "print(df[nominal_cols + list(ordinal_asc) + list(ordinal_desc) + numeric_cols].dtypes)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f948a4b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 321457 entries, 0 to 441455\n",
      "Data columns (total 59 columns):\n",
      " #   Column      Non-Null Count   Dtype  \n",
      "---  ------      --------------   -----  \n",
      " 0   _STATE      321457 non-null  float64\n",
      " 1   GENHLTH     320707 non-null  float64\n",
      " 2   PHYSHLTH    315181 non-null  float64\n",
      " 3   MENTHLTH    316891 non-null  float64\n",
      " 4   HLTHPLN1    320798 non-null  Int64  \n",
      " 5   PERSDOC2    320512 non-null  Int64  \n",
      " 6   MEDCOST     320812 non-null  Int64  \n",
      " 7   CHECKUP1    318370 non-null  float64\n",
      " 8   BPHIGH4     320806 non-null  Int64  \n",
      " 9   BLOODCHO    321457 non-null  Int64  \n",
      " 10  CHOLCHK     317268 non-null  float64\n",
      " 11  TOLDHI2     318789 non-null  Int64  \n",
      " 12  CVDINFR4    320086 non-null  Int64  \n",
      " 13  CVDCRHD4    318652 non-null  Int64  \n",
      " 14  CVDSTRK3    320613 non-null  Int64  \n",
      " 15  ASTHMA3     320590 non-null  Int64  \n",
      " 16  CHCSCNCR    320631 non-null  Int64  \n",
      " 17  CHCOCNCR    320822 non-null  Int64  \n",
      " 18  CHCCOPD1    319944 non-null  Int64  \n",
      " 19  HAVARTH3    319679 non-null  Int64  \n",
      " 20  ADDEPEV2    320240 non-null  Int64  \n",
      " 21  CHCKIDNY    320461 non-null  Int64  \n",
      " 22  DIABETE3    321457 non-null  object \n",
      " 23  SEX         321457 non-null  float64\n",
      " 24  MARITAL     320277 non-null  float64\n",
      " 25  EDUCA       320862 non-null  float64\n",
      " 26  VETERAN3    321236 non-null  Int64  \n",
      " 27  EMPLOY1     320039 non-null  float64\n",
      " 28  CHILDREN    320717 non-null  float64\n",
      " 29  INCOME2     276347 non-null  float64\n",
      " 30  INTERNET    321001 non-null  Int64  \n",
      " 31  QLACTLM2    319672 non-null  Int64  \n",
      " 32  USEEQUIP    320998 non-null  Int64  \n",
      " 33  BLIND       320548 non-null  Int64  \n",
      " 34  DECIDE      319749 non-null  Int64  \n",
      " 35  DIFFWALK    320049 non-null  Int64  \n",
      " 36  DIFFDRES    320868 non-null  Int64  \n",
      " 37  DIFFALON    320423 non-null  Int64  \n",
      " 38  SMOKE100    319492 non-null  Int64  \n",
      " 39  USENOW3     320357 non-null  float64\n",
      " 40  ALCDAY5     311116 non-null  float64\n",
      " 41  FRUITJU1    313269 non-null  float64\n",
      " 42  FRUIT1      315117 non-null  float64\n",
      " 43  FVBEANS     311545 non-null  float64\n",
      " 44  FVGREEN     314571 non-null  float64\n",
      " 45  FVORANG     313717 non-null  float64\n",
      " 46  VEGETAB1    314219 non-null  float64\n",
      " 47  EXERANY2    319909 non-null  Int64  \n",
      " 48  STRENGTH    309017 non-null  float64\n",
      " 49  SEATBELT    320009 non-null  float64\n",
      " 50  FLUSHOT6    319573 non-null  Int64  \n",
      " 51  PNEUVAC3    296843 non-null  Int64  \n",
      " 52  HIVTST6     310240 non-null  Int64  \n",
      " 53  _RACE       317366 non-null  float64\n",
      " 54  _AGE_G      321457 non-null  float64\n",
      " 55  _BMI5CAT    321457 non-null  float64\n",
      " 56  _SMOKER3    319296 non-null  float64\n",
      " 57  _PACAT1     308780 non-null  float64\n",
      " 58  NUMADULT_2  321457 non-null  float64\n",
      "dtypes: Int64(30), float64(28), object(1)\n",
      "memory usage: 156.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "99b779fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_STATE</th>\n",
       "      <th>GENHLTH</th>\n",
       "      <th>PHYSHLTH</th>\n",
       "      <th>MENTHLTH</th>\n",
       "      <th>HLTHPLN1</th>\n",
       "      <th>PERSDOC2</th>\n",
       "      <th>MEDCOST</th>\n",
       "      <th>CHECKUP1</th>\n",
       "      <th>BPHIGH4</th>\n",
       "      <th>BLOODCHO</th>\n",
       "      <th>...</th>\n",
       "      <th>SEATBELT</th>\n",
       "      <th>FLUSHOT6</th>\n",
       "      <th>PNEUVAC3</th>\n",
       "      <th>HIVTST6</th>\n",
       "      <th>_RACE</th>\n",
       "      <th>_AGE_G</th>\n",
       "      <th>_BMI5CAT</th>\n",
       "      <th>_SMOKER3</th>\n",
       "      <th>_PACAT1</th>\n",
       "      <th>NUMADULT_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   _STATE  GENHLTH  PHYSHLTH  MENTHLTH  HLTHPLN1  PERSDOC2  MEDCOST  CHECKUP1  \\\n",
       "0     1.0      5.0      15.0      18.0         1         1        0       1.0   \n",
       "1     1.0      3.0       0.0       0.0         0         1        1       4.0   \n",
       "3     1.0      5.0      30.0      30.0         1         1        1       1.0   \n",
       "4     1.0      5.0      20.0       0.0         1         1        0       1.0   \n",
       "5     1.0      2.0       0.0       0.0         1         1        0       1.0   \n",
       "\n",
       "   BPHIGH4  BLOODCHO  ...  SEATBELT  FLUSHOT6  PNEUVAC3  HIVTST6  _RACE  \\\n",
       "0        1         1  ...       1.0         1         1        1    1.0   \n",
       "1        0         1  ...       3.0         0         0        0    1.0   \n",
       "3        1         1  ...       1.0         1         1     <NA>    1.0   \n",
       "4        0         1  ...       1.0         0         1        1    1.0   \n",
       "5        1         1  ...       1.0         1         1        0    1.0   \n",
       "\n",
       "   _AGE_G  _BMI5CAT  _SMOKER3  _PACAT1  NUMADULT_2  \n",
       "0     5.0       4.0       3.0      4.0         3.0  \n",
       "1     4.0       3.0       1.0      2.0         1.0  \n",
       "3     5.0       3.0       4.0      4.0         3.0  \n",
       "4     5.0       2.0       4.0      4.0         2.0  \n",
       "5     6.0       3.0       4.0      1.0         1.0  \n",
       "\n",
       "[5 rows x 59 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cb322d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('cleaned_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1fe7da62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.,  1.,  2.,  4.,  5.,  6.,  8.,  7., 12., 14., 77., 11., 99.,\n",
       "       13., 18.,  9., 10., 15., 20., 25., 39., 60., 16.])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['CHILDREN'].unique()\n",
    "df['NUMADULT_2'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "087c9966",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  4., nan,  3.,  2.])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['CHOLCHK'].unique()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DMML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
